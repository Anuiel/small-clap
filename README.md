## How to try

Download dataset and prepere it with encoders. For Audiocaps i suggest using val or test part, train is too massive to precalculate all embeddings.

Then install all requirements in `requirements.txt` file.

After that go to inference.ipynb notebook and try different text inputs. 

## Dataset

Data can be found [there](https://github.com/OFA-Sys/ONE-PEACE/blob/main/datasets.md#:~:text=Dataset%20for%20AudioCaps)

## Weights

For text and audio encoder model weights are downloded with hugging face. Projector weights are part of a release that can be found [there](https://github.com/Anuiel/small-clap/releases/tag/Main)
